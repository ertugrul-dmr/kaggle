{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021791,
     "end_time": "2020-09-20T15:37:43.941686",
     "exception": false,
     "start_time": "2020-09-20T15:37:43.919895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "#### This is my final model I built in my last week of competition. It's little different than my first public model I shared [here](https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble). Basically this model includes meta as well as image, attention layers and progressive sprinkles augmentation. It gave me pretty stable cv and lb so I used them on my final ensembles. I explained how did I come up with this idea [here](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/175361).\n",
    "\n",
    "#### Thanks to all who shared their work and ideas to the community. I tried to reference every single work helped me on this work so you can find the links in comments at relevant code cells...\n",
    "\n",
    "#### I'm going to keep this notebook simple without many markdowns unlike my old public notebooks, since I shared my analysis about the competition before I thought sharing code only model at final notebook would be better.\n",
    "\n",
    "### This is light version the model I used in my ensembles, this one uses 256x images and lower EfficientNet B's...\n",
    "#### In actual competition I ensembled different image sizes with different EfficientNet's..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-20T15:37:43.988822Z",
     "iopub.status.busy": "2020-09-20T15:37:43.988177Z",
     "iopub.status.idle": "2020-09-20T15:37:53.266493Z",
     "shell.execute_reply": "2020-09-20T15:37:53.265741Z"
    },
    "papermill": {
     "duration": 9.303981,
     "end_time": "2020-09-20T15:37:53.266616",
     "exception": false,
     "start_time": "2020-09-20T15:37:43.962635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow~=2.2.0 in /opt/conda/lib/python3.7/site-packages (2.2.0)\r\n",
      "Collecting tensorflow_gcs_config~=2.2.0\r\n",
      "  Downloading tensorflow_gcs_config-2.2.0-py3-none-any.whl (392 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 392 kB 402 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (3.12.2)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.30.0)\r\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.4.1)\r\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.6.3)\r\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (2.10.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.14.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (0.2.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.11.2)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.1.2)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.1.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (3.3.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (1.18.5)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (0.34.2)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (0.3.3)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (0.9.0)\r\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (2.2.2)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.2.0) (2.2.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow~=2.2.0) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (2.23.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.14.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (0.4.1)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.0.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.2.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.7.0)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.24.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (4.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.1.1)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.0.1)\r\n",
      "Installing collected packages: tensorflow-gcs-config\r\n",
      "  Attempting uninstall: tensorflow-gcs-config\r\n",
      "    Found existing installation: tensorflow-gcs-config 2.1.7\r\n",
      "    Uninstalling tensorflow-gcs-config-2.1.7:\r\n",
      "      Successfully uninstalled tensorflow-gcs-config-2.1.7\r\n",
      "Successfully installed tensorflow-gcs-config-2.2.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-20T15:37:53.332185Z",
     "iopub.status.busy": "2020-09-20T15:37:53.331437Z",
     "iopub.status.idle": "2020-09-20T15:38:13.840065Z",
     "shell.execute_reply": "2020-09-20T15:38:13.839403Z"
    },
    "papermill": {
     "duration": 20.545945,
     "end_time": "2020-09-20T15:38:13.840174",
     "exception": false,
     "start_time": "2020-09-20T15:37:53.294229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: pandas_summary in /opt/conda/lib/python3.7/site-packages (0.0.7)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pandas_summary) (1.0.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pandas_summary) (1.18.5)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->pandas_summary) (2019.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->pandas_summary) (2.8.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->pandas_summary) (1.14.0)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons) (2.9.1)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet\n",
    "!pip install pandas_summary\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:13.908212Z",
     "iopub.status.busy": "2020-09-20T15:38:13.907579Z",
     "iopub.status.idle": "2020-09-20T15:38:20.889084Z",
     "shell.execute_reply": "2020-09-20T15:38:20.888459Z"
    },
    "papermill": {
     "duration": 7.0183,
     "end_time": "2020-09-20T15:38:20.889235",
     "exception": false,
     "start_time": "2020-09-20T15:38:13.870935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading packages\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:20.966482Z",
     "iopub.status.busy": "2020-09-20T15:38:20.965459Z",
     "iopub.status.idle": "2020-09-20T15:38:20.968364Z",
     "shell.execute_reply": "2020-09-20T15:38:20.968874Z"
    },
    "papermill": {
     "duration": 0.044063,
     "end_time": "2020-09-20T15:38:20.969018",
     "exception": false,
     "start_time": "2020-09-20T15:38:20.924955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    \n",
    "    ''' A function to seed everything for getting reproducible results. '''\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = str(seed)\n",
    "    os.environ['TF_KERAS'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:21.144323Z",
     "iopub.status.busy": "2020-09-20T15:38:21.143697Z",
     "iopub.status.idle": "2020-09-20T15:38:26.056496Z",
     "shell.execute_reply": "2020-09-20T15:38:26.055848Z"
    },
    "papermill": {
     "duration": 5.054614,
     "end_time": "2020-09-20T15:38:26.056615",
     "exception": false,
     "start_time": "2020-09-20T15:38:21.002001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to TPU...\n",
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "initializing  TPU ...\n",
      "TPU initialized\n",
      "Mixed precision enabled\n",
      "Accelerated Linear Algebra enabled\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'TPU'\n",
    "MIXED_PRECISION = True\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "# We set our TPU settings here mixed_precision let's us bigger batches\n",
    "\n",
    "if DEVICE == 'TPU':\n",
    "    print('Connecting to TPU...')\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print('Could not connect to TPU')\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print('initializing  TPU ...')\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)            \n",
    "            print('TPU initialized')\n",
    "            if MIXED_PRECISION:\n",
    "                from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "                policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "                mixed_precision.set_policy(policy)\n",
    "                print('Mixed precision enabled')\n",
    "            if XLA_ACCELERATE:\n",
    "                    tf.config.optimizer.set_jit(True)\n",
    "                    print('Accelerated Linear Algebra enabled')\n",
    "                 \n",
    "        except _:\n",
    "            print('failed to initialize TPU')\n",
    "    else:\n",
    "        DEVICE = 'GPU'\n",
    "\n",
    "if DEVICE != 'TPU':\n",
    "    print('Using default strategy for CPU and single GPU')\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == 'GPU':\n",
    "    print('Num GPUs Available: ', len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    if MIXED_PRECISION:\n",
    "        from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "        mixed_precision.set_policy(policy)\n",
    "        print('Mixed precision enabled')\n",
    "    if XLA_ACCELERATE:\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        print('Accelerated Linear Algebra enabled')\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03221,
     "end_time": "2020-09-20T15:38:26.120279",
     "exception": false,
     "start_time": "2020-09-20T15:38:26.088069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:26.189898Z",
     "iopub.status.busy": "2020-09-20T15:38:26.189150Z",
     "iopub.status.idle": "2020-09-20T15:38:26.192630Z",
     "shell.execute_reply": "2020-09-20T15:38:26.191978Z"
    },
    "papermill": {
     "duration": 0.041101,
     "end_time": "2020-09-20T15:38:26.192739",
     "exception": false,
     "start_time": "2020-09-20T15:38:26.151638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some modelling and augmentation parameters\n",
    "\n",
    "CFG = dict(\n",
    "    epochs = 30,\n",
    "    batch_size = 128,\n",
    "    lr = 0.00032,  # learning rate  \n",
    "    inp_size = 256, # input image size\n",
    "\n",
    "    \n",
    "    eff_B = 0, #effnet to choose eg. B1-B2-...-B7\n",
    "    \n",
    "    \n",
    "    sprinkles_mode    = 'normal',\n",
    "    sprinkles_prob    =   1, # probability to spawn a box (between 0-1)\n",
    "    num_holes         =   5, # number of boxes to drop\n",
    "    side_length       =   256//10   #dropout box size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030871,
     "end_time": "2020-09-20T15:38:26.255467",
     "exception": false,
     "start_time": "2020-09-20T15:38:26.224596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:26.332158Z",
     "iopub.status.busy": "2020-09-20T15:38:26.331428Z",
     "iopub.status.idle": "2020-09-20T15:38:29.759854Z",
     "shell.execute_reply": "2020-09-20T15:38:29.759172Z"
    },
    "papermill": {
     "duration": 3.47264,
     "end_time": "2020-09-20T15:38:29.759962",
     "exception": false,
     "start_time": "2020-09-20T15:38:26.287322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASEPATH = '../input/siim-isic-melanoma-classification'\n",
    "df_train = pd.read_csv(os.path.join(BASEPATH, 'train.csv'))\n",
    "df_test  = pd.read_csv(os.path.join(BASEPATH, 'test.csv'))\n",
    "df_sub   = pd.read_csv(os.path.join(BASEPATH, 'sample_submission.csv'))\n",
    "\n",
    "# Data from Chris' tfrecords\n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-%ix%i'%(CFG['inp_size'],CFG['inp_size'])) # main train data\n",
    "GCS_PATHE = KaggleDatasets().get_gcs_path('isic2019-%ix%i'%(CFG['inp_size'],CFG['inp_size'])) # external data\n",
    "\n",
    "\n",
    "# Training files directory\n",
    "training_files = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
    "training_files_2018 = tf.io.gfile.glob(GCS_PATHE + '/train%.2i*.tfrec'%(2*x) for x in range(15))\n",
    "\n",
    "training_files += training_files_2018\n",
    "\n",
    "\n",
    "\n",
    "# test files directory\n",
    "test_files = tf.io.gfile.glob(GCS_PATH + '/test*.tfrec') # test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031078,
     "end_time": "2020-09-20T15:38:29.822548",
     "exception": false,
     "start_time": "2020-09-20T15:38:29.791470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:29.909860Z",
     "iopub.status.busy": "2020-09-20T15:38:29.908846Z",
     "iopub.status.idle": "2020-09-20T15:38:29.912096Z",
     "shell.execute_reply": "2020-09-20T15:38:29.911593Z"
    },
    "papermill": {
     "duration": 0.058468,
     "end_time": "2020-09-20T15:38:29.912209",
     "exception": false,
     "start_time": "2020-09-20T15:38:29.853741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Progressive sprinkles implementation from here:\n",
    "# https://www.kaggle.com/benboren/tfrecord-progressive-sprinkles\n",
    "\n",
    "def make_mask(num_holes,side_length,rows, cols, num_channels):\n",
    "        '''Builds the mask for all sprinkles.'''\n",
    "        row_range = tf.tile(tf.range(rows)[..., tf.newaxis], [1, num_holes])\n",
    "        col_range = tf.tile(tf.range(cols)[..., tf.newaxis], [1, num_holes])\n",
    "        r_idx = tf.random.uniform([num_holes], minval=0, maxval=rows-1,\n",
    "                                  dtype=tf.int32)\n",
    "        c_idx = tf.random.uniform([num_holes], minval=0, maxval=cols-1,\n",
    "                                  dtype=tf.int32)\n",
    "        r1 = tf.clip_by_value(r_idx - side_length // 2, 0, rows)\n",
    "        r2 = tf.clip_by_value(r_idx + side_length // 2, 0, rows)\n",
    "        c1 = tf.clip_by_value(c_idx - side_length // 2, 0, cols)\n",
    "        c2 = tf.clip_by_value(c_idx + side_length // 2, 0, cols)\n",
    "        row_mask = (row_range > r1) & (row_range < r2)\n",
    "        col_mask = (col_range > c1) & (col_range < c2)\n",
    "\n",
    "        # Combine masks into one layer and duplicate over channels.\n",
    "        mask = row_mask[:, tf.newaxis] & col_mask\n",
    "        mask = tf.reduce_any(mask, axis=-1)\n",
    "        mask = mask[..., tf.newaxis]\n",
    "        mask = tf.tile(mask, [1, 1, num_channels])\n",
    "        return mask\n",
    "    \n",
    "def sprinkles(image, cfg = CFG): \n",
    "    \n",
    "    '''Applies all sprinkles.'''\n",
    "    \n",
    "    num_holes = cfg['num_holes']\n",
    "    side_length = cfg['side_length']\n",
    "    mode = cfg['sprinkles_mode']\n",
    "    PROBABILITY = cfg['sprinkles_prob']\n",
    "    \n",
    "    RandProb = tf.cast( tf.random.uniform([],0,1) < PROBABILITY, tf.int32)\n",
    "    if (RandProb == 0)|(num_holes == 0): return image\n",
    "    \n",
    "    img_shape = tf.shape(image)\n",
    "    if mode is 'normal':\n",
    "        rejected = tf.zeros_like(image)\n",
    "    elif mode is 'salt_pepper':\n",
    "        num_holes = num_holes // 2\n",
    "        rejected_high = tf.ones_like(image)\n",
    "        rejected_low = tf.zeros_like(image)\n",
    "    elif mode is 'gaussian':\n",
    "        rejected = tf.random.normal(img_shape, dtype=tf.float32)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown mode \"{mode}\" given.')\n",
    "        \n",
    "    rows = img_shape[0]\n",
    "    cols = img_shape[1]\n",
    "    num_channels = img_shape[-1]\n",
    "    if mode is 'salt_pepper':\n",
    "        mask1 = make_mask(num_holes,side_length,rows, cols, num_channels)\n",
    "        mask2 = make_mask(num_holes,side_length,rows, cols, num_channels)\n",
    "        filtered_image = tf.where(mask1, rejected_high, image)\n",
    "        filtered_image = tf.where(mask2, rejected_low, filtered_image)\n",
    "    else:\n",
    "        mask = make_mask(num_holes,side_length,rows, cols, num_channels)\n",
    "        filtered_image = tf.where(mask, rejected, image)\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:29.987796Z",
     "iopub.status.busy": "2020-09-20T15:38:29.982325Z",
     "iopub.status.idle": "2020-09-20T15:38:29.990734Z",
     "shell.execute_reply": "2020-09-20T15:38:29.990083Z"
    },
    "papermill": {
     "duration": 0.047243,
     "end_time": "2020-09-20T15:38:29.990840",
     "exception": false,
     "start_time": "2020-09-20T15:38:29.943597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    \n",
    "    # Most of the augmentations and transforms from here:\n",
    "    # https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)    \n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.071636Z",
     "iopub.status.busy": "2020-09-20T15:38:30.070551Z",
     "iopub.status.idle": "2020-09-20T15:38:30.073909Z",
     "shell.execute_reply": "2020-09-20T15:38:30.073425Z"
    },
    "papermill": {
     "duration": 0.052023,
     "end_time": "2020-09-20T15:38:30.074018",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.021995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = CFG['inp_size']\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        rot = 15. * tf.random.normal([1],dtype='float32')\n",
    "    else:\n",
    "        rot = 180. * tf.random.normal([1],dtype='float32')\n",
    "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image['img_inp'],tf.transpose(idx3))\n",
    "        \n",
    "    return {'img_inp': tf.reshape(d,[DIM,DIM,3]), 'meta_inp': image['meta_inp']}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.143826Z",
     "iopub.status.busy": "2020-09-20T15:38:30.143170Z",
     "iopub.status.idle": "2020-09-20T15:38:30.145979Z",
     "shell.execute_reply": "2020-09-20T15:38:30.146451Z"
    },
    "papermill": {
     "duration": 0.041182,
     "end_time": "2020-09-20T15:38:30.146583",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.105401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    \n",
    "    '''A function for loading image, decode and reshape'''\n",
    "    \n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    # normalizing image\n",
    "    image = tf.cast(image, tf.float32) / 255.0 \n",
    "    # explicit input size for TPU\n",
    "    image = tf.reshape(image, [CFG['inp_size'], CFG['inp_size'], 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.218549Z",
     "iopub.status.busy": "2020-09-20T15:38:30.217847Z",
     "iopub.status.idle": "2020-09-20T15:38:30.220534Z",
     "shell.execute_reply": "2020-09-20T15:38:30.220940Z"
    },
    "papermill": {
     "duration": 0.04354,
     "end_time": "2020-09-20T15:38:30.221066",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.177526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_augment(data, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement \n",
    "    # in the next function (below), this happens essentially for free on TPU. \n",
    "    # Data pipeline code is executed on the 'CPU' part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    # https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "    \n",
    "    data['img_inp'] = tf.image.random_flip_left_right(data['img_inp'])\n",
    "    data['img_inp'] = tf.image.random_flip_up_down(data['img_inp'])\n",
    "    data['img_inp'] = tf.image.random_hue(data['img_inp'], 0.01)\n",
    "    data['img_inp'] = tf.image.random_saturation(data['img_inp'], 0.7, 1.3)\n",
    "    data['img_inp'] = tf.image.random_contrast(data['img_inp'], 0.8, 1.2)\n",
    "    data['img_inp'] = tf.image.random_brightness(data['img_inp'], 0.1)\n",
    "    data['img_inp'] = sprinkles(data['img_inp']) \n",
    "\n",
    "    \n",
    "    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03094,
     "end_time": "2020-09-20T15:38:30.282847",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.251907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.358335Z",
     "iopub.status.busy": "2020-09-20T15:38:30.357628Z",
     "iopub.status.idle": "2020-09-20T15:38:30.360763Z",
     "shell.execute_reply": "2020-09-20T15:38:30.360195Z"
    },
    "papermill": {
     "duration": 0.046502,
     "end_time": "2020-09-20T15:38:30.360863",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.314361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    \n",
    "    '''A function to parse images and returns targets together'''\n",
    "    \n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        # tf.string means bytestring\n",
    "        'image': tf.io.FixedLenFeature([], tf.string), \n",
    "        # shape [] means single element\n",
    "        'target': tf.io.FixedLenFeature([], tf.int64),\n",
    "        # meta features\n",
    "        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64)\n",
    "        \n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    # dictionary for meta images\n",
    "    data = {}\n",
    "    data['age_approx'] = tf.cast(example['age_approx'], tf.int32)\n",
    "    data['sex'] = tf.cast(example['sex'], tf.int32)\n",
    "    data['anatom_site_general_challenge'] = tf.cast(tf.one_hot(example['anatom_site_general_challenge'], 7), tf.int32)\n",
    "    # returns a dataset of (image, label, data)\n",
    "    return image, label, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.436988Z",
     "iopub.status.busy": "2020-09-20T15:38:30.436344Z",
     "iopub.status.idle": "2020-09-20T15:38:30.439529Z",
     "shell.execute_reply": "2020-09-20T15:38:30.438933Z"
    },
    "papermill": {
     "duration": 0.046536,
     "end_time": "2020-09-20T15:38:30.439646",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.393110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_unlabeled_tfrecord(example):\n",
    "    \n",
    "    '''A function to parse images and returns image ids together'''\n",
    "    \n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        # tf.string means bytestring\n",
    "        'image': tf.io.FixedLenFeature([], tf.string), \n",
    "        # shape [] means single element\n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        # meta features\n",
    "        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    image_name = example['image_name']\n",
    "    # dictionary for meta images\n",
    "    data = {}\n",
    "    data['age_approx'] = tf.cast(example['age_approx'], tf.int32)\n",
    "    data['sex'] = tf.cast(example['sex'], tf.int32)\n",
    "    data['anatom_site_general_challenge'] = tf.cast(tf.one_hot(example['anatom_site_general_challenge'], 7), tf.int32)\n",
    "    # returns a dataset of (image, key, data)\n",
    "    return image, image_name, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.517707Z",
     "iopub.status.busy": "2020-09-20T15:38:30.516742Z",
     "iopub.status.idle": "2020-09-20T15:38:30.519910Z",
     "shell.execute_reply": "2020-09-20T15:38:30.519371Z"
    },
    "papermill": {
     "duration": 0.047532,
     "end_time": "2020-09-20T15:38:30.520018",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.472486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_complete_tfrecord(example):\n",
    "    \n",
    "    '''A function to parse images and returns image ids as well as targets together'''\n",
    "    \n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string), \n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string), \n",
    "        'target': tf.io.FixedLenFeature([], tf.int64), \n",
    "        # meta features\n",
    "        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    image_name = example['image_name']\n",
    "    target = tf.cast(example['target'], tf.int32)\n",
    "    # dictionary for meta images\n",
    "    data = {}\n",
    "    data['age_approx'] = tf.cast(example['age_approx'], tf.int32)\n",
    "    data['sex'] = tf.cast(example['sex'], tf.int32)\n",
    "    data['anatom_site_general_challenge'] = tf.cast(tf.one_hot(example['anatom_site_general_challenge'], 7), tf.int32)\n",
    "    return image, image_name, target, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.595507Z",
     "iopub.status.busy": "2020-09-20T15:38:30.594460Z",
     "iopub.status.idle": "2020-09-20T15:38:30.597682Z",
     "shell.execute_reply": "2020-09-20T15:38:30.597039Z"
    },
    "papermill": {
     "duration": 0.04491,
     "end_time": "2020-09-20T15:38:30.597788",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.552878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled = True, ordered = False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # Diregarding data order. Order does not matter since we will be shuffling the data anyway\n",
    "    \n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        # disable order, increase speed\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    # use data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    # returns a dataset of (image, label) pairs if labeled = True or (image, id) pair if labeld = False\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls = AUTO) \n",
    "    return dataset\n",
    "\n",
    "def load_complete_dataset(filenames):        \n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    # returns a dataset of (image_name, target)\n",
    "    dataset = dataset.map(read_complete_tfrecord, num_parallel_calls = AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.672116Z",
     "iopub.status.busy": "2020-09-20T15:38:30.671273Z",
     "iopub.status.idle": "2020-09-20T15:38:30.674345Z",
     "shell.execute_reply": "2020-09-20T15:38:30.673790Z"
    },
    "papermill": {
     "duration": 0.04406,
     "end_time": "2020-09-20T15:38:30.674453",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.630393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_input(image, label, data):\n",
    "    \n",
    "    ''' A function for extracing metadata as well as images for train'''\n",
    "    \n",
    "    anatom = [tf.cast(data['anatom_site_general_challenge'][i], dtype = tf.float32) for i in range(7)]\n",
    "    \n",
    "    tab_data = [tf.cast(data[tfeat], dtype = tf.float32) for tfeat in ['age_approx', 'sex']]\n",
    "    \n",
    "    tabular = tf.stack(tab_data + anatom)\n",
    "    \n",
    "    return {'img_inp': image, 'meta_inp':  tabular}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.748757Z",
     "iopub.status.busy": "2020-09-20T15:38:30.747736Z",
     "iopub.status.idle": "2020-09-20T15:38:30.750888Z",
     "shell.execute_reply": "2020-09-20T15:38:30.750221Z"
    },
    "papermill": {
     "duration": 0.043606,
     "end_time": "2020-09-20T15:38:30.751008",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.707402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_input(image, image_name, data):\n",
    "    \n",
    "    ''' A function for extracing metadata as well as images for test'''\n",
    "    \n",
    "\n",
    "    anatom = [tf.cast(data['anatom_site_general_challenge'][i], dtype = tf.float32) for i in range(7)]\n",
    "    \n",
    "    tab_data = [tf.cast(data[tfeat], dtype = tf.float32) for tfeat in ['age_approx', 'sex']]\n",
    "    \n",
    "    tabular = tf.stack(tab_data + anatom)\n",
    "    \n",
    "    return {'img_inp': image, 'meta_inp':  tabular}, image_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.826324Z",
     "iopub.status.busy": "2020-09-20T15:38:30.825295Z",
     "iopub.status.idle": "2020-09-20T15:38:30.828120Z",
     "shell.execute_reply": "2020-09-20T15:38:30.827456Z"
    },
    "papermill": {
     "duration": 0.043803,
     "end_time": "2020-09-20T15:38:30.828228",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.784425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_input(image, image_name, target, data):\n",
    "    \n",
    "    ''' A function for extracing metadata as well as images for validation'''    \n",
    "\n",
    "    anatom = [tf.cast(data['anatom_site_general_challenge'][i], dtype = tf.float32) for i in range(7)]\n",
    "    \n",
    "    tab_data = [tf.cast(data[tfeat], dtype = tf.float32) for tfeat in ['age_approx', 'sex']]\n",
    "    \n",
    "    tabular = tf.stack(tab_data + anatom)\n",
    "    \n",
    "    return {'img_inp': image, 'meta_inp':  tabular}, image_name, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.911806Z",
     "iopub.status.busy": "2020-09-20T15:38:30.911056Z",
     "iopub.status.idle": "2020-09-20T15:38:30.914388Z",
     "shell.execute_reply": "2020-09-20T15:38:30.913645Z"
    },
    "papermill": {
     "duration": 0.052807,
     "end_time": "2020-09-20T15:38:30.914509",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.861702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_dataset(filenames, labeled = True, ordered = False):\n",
    "    \n",
    "    '''Gets the data for training phrase, applies augment, transformation and shuffle'''\n",
    "    \n",
    "    dataset = load_dataset(filenames, labeled = labeled, ordered = ordered)\n",
    "    dataset = dataset.map(training_input, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.map(transform, num_parallel_calls = AUTO)\n",
    "    # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.repeat() \n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(CFG['batch_size'])\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_validation_dataset(filenames, labeled = True, ordered = True):\n",
    "    \n",
    "    '''Gets the data for validation phrase'''\n",
    "    \n",
    "    dataset = load_dataset(filenames, labeled = labeled, ordered = ordered)\n",
    "    dataset = dataset.map(training_input, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(CFG['batch_size'])\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(filenames, labeled = False, ordered = True):\n",
    "    \n",
    "    '''Gets the data for testing phrase, no augmentations since no TTA'''\n",
    "    \n",
    "    dataset = load_dataset(filenames, labeled = labeled, ordered = ordered)\n",
    "    dataset = dataset.map(test_input, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(CFG['batch_size'])\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset\n",
    "\n",
    "def get_complete_dataset(filenames):\n",
    "    dataset = load_complete_dataset(filenames)\n",
    "    dataset = dataset.map(validation_input, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(CFG['batch_size'])\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:30.989261Z",
     "iopub.status.busy": "2020-09-20T15:38:30.988289Z",
     "iopub.status.idle": "2020-09-20T15:38:30.991128Z",
     "shell.execute_reply": "2020-09-20T15:38:30.991633Z"
    },
    "papermill": {
     "duration": 0.043221,
     "end_time": "2020-09-20T15:38:30.991775",
     "exception": false,
     "start_time": "2020-09-20T15:38:30.948554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    \n",
    "    ''' The number of data items is written in the name of the .tfrec files '''\n",
    "    \n",
    "    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:31.067712Z",
     "iopub.status.busy": "2020-09-20T15:38:31.066854Z",
     "iopub.status.idle": "2020-09-20T15:38:31.071484Z",
     "shell.execute_reply": "2020-09-20T15:38:31.070964Z"
    },
    "papermill": {
     "duration": 0.045798,
     "end_time": "2020-09-20T15:38:31.071603",
     "exception": false,
     "start_time": "2020-09-20T15:38:31.025805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 36440 training images, 9110 validation images, 10982 unlabeled test images\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_IMAGES = int(count_data_items(training_files) * 0.8)\n",
    "# use validation data for training\n",
    "NUM_VALIDATION_IMAGES = int(count_data_items(training_files) * 0.2)\n",
    "NUM_TEST_IMAGES = count_data_items(test_files)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG['batch_size']\n",
    "\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034472,
     "end_time": "2020-09-20T15:38:31.140372",
     "exception": false,
     "start_time": "2020-09-20T15:38:31.105900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Sprinkles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:31.218632Z",
     "iopub.status.busy": "2020-09-20T15:38:31.217617Z",
     "iopub.status.idle": "2020-09-20T15:38:31.220876Z",
     "shell.execute_reply": "2020-09-20T15:38:31.220226Z"
    },
    "papermill": {
     "duration": 0.04672,
     "end_time": "2020-09-20T15:38:31.220985",
     "exception": false,
     "start_time": "2020-09-20T15:38:31.174265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IncreaseSprinklesHoles(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        ''' Custom callback for progressive sprinkles increases with epoch'''\n",
    "      \n",
    "        if epoch <= 10:\n",
    "            CFG['num_holes'] = epoch  + 5\n",
    "            CFG['side_length'] = (CFG['inp_size'] // 10) + (epoch // 2)\n",
    "        if epoch >= 10:\n",
    "            CFG['num_holes'] = epoch  + 5\n",
    "            CFG['side_length'] = (CFG['inp_size'] // 5) + (epoch // 2)\n",
    "        if epoch >= 15:\n",
    "            CFG['num_holes'] = epoch  + 5\n",
    "            CFG['side_length'] = (CFG['inp_size'] // 2) + (epoch // 2)\n",
    "        \n",
    "sprinkles_cb = IncreaseSprinklesHoles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033897,
     "end_time": "2020-09-20T15:38:31.289054",
     "exception": false,
     "start_time": "2020-09-20T15:38:31.255157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modelling and OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T15:38:31.414823Z",
     "iopub.status.busy": "2020-09-20T15:38:31.371489Z",
     "iopub.status.idle": "2020-09-20T16:15:23.685602Z",
     "shell.execute_reply": "2020-09-20T16:15:23.684937Z"
    },
    "papermill": {
     "duration": 2212.362554,
     "end_time": "2020-09-20T16:15:23.685710",
     "exception": false,
     "start_time": "2020-09-20T15:38:31.323156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 1\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_noisy-student_notop.h5\n",
      "16703488/16696600 [==============================] - 1s 0us/step\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 47s 164ms/step - auc: 0.8286 - loss: 0.0172 - val_auc: 0.8604 - val_loss: 0.0172 - lr: 3.2000e-04\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 32s 112ms/step - auc: 0.8638 - loss: 0.0150 - val_auc: 0.8965 - val_loss: 0.0156 - lr: 3.2000e-04\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 34s 119ms/step - auc: 0.8799 - loss: 0.0139 - val_auc: 0.9049 - val_loss: 0.0144 - lr: 3.2000e-04\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 31s 110ms/step - auc: 0.8874 - loss: 0.0140 - val_auc: 0.9023 - val_loss: 0.0147 - lr: 3.2000e-04\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 34s 118ms/step - auc: 0.8989 - loss: 0.0125 - val_auc: 0.9061 - val_loss: 0.0153 - lr: 3.2000e-04\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 34s 118ms/step - auc: 0.8984 - loss: 0.0126 - val_auc: 0.9099 - val_loss: 0.0141 - lr: 3.2000e-04\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 33s 117ms/step - auc: 0.9035 - loss: 0.0124 - val_auc: 0.9130 - val_loss: 0.0159 - lr: 3.2000e-04\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 34s 120ms/step - auc: 0.9072 - loss: 0.0128 - val_auc: 0.8826 - val_loss: 0.0163 - lr: 3.2000e-04\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 33s 117ms/step - auc: 0.9167 - loss: 0.0119 - val_auc: 0.9163 - val_loss: 0.0152 - lr: 3.2000e-04\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 33s 115ms/step - auc: 0.9170 - loss: 0.0121 - val_auc: 0.9034 - val_loss: 0.0179 - lr: 3.2000e-04\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9136 - loss: 0.0121\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00019199999514967202.\n",
      "284/284 [==============================] - 32s 113ms/step - auc: 0.9136 - loss: 0.0121 - val_auc: 0.8319 - val_loss: 0.0191 - lr: 3.2000e-04\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 34s 120ms/step - auc: 0.9241 - loss: 0.0109 - val_auc: 0.9217 - val_loss: 0.0136 - lr: 1.9200e-04\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 33s 115ms/step - auc: 0.9310 - loss: 0.0104 - val_auc: 0.9211 - val_loss: 0.0138 - lr: 1.9200e-04\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 34s 119ms/step - auc: 0.9314 - loss: 0.0109 - val_auc: 0.9247 - val_loss: 0.0180 - lr: 1.9200e-04\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 30s 106ms/step - auc: 0.9376 - loss: 0.0104 - val_auc: 0.9121 - val_loss: 0.0164 - lr: 1.9200e-04\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9397 - loss: 0.0101\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00011519999534357338.\n",
      "284/284 [==============================] - 32s 113ms/step - auc: 0.9397 - loss: 0.0101 - val_auc: 0.9156 - val_loss: 0.0145 - lr: 1.9200e-04\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 32s 113ms/step - auc: 0.9449 - loss: 0.0100 - val_auc: 0.9312 - val_loss: 0.0138 - lr: 1.1520e-04\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 31s 110ms/step - auc: 0.9518 - loss: 0.0089 - val_auc: 0.9233 - val_loss: 0.0153 - lr: 1.1520e-04\n",
      "Epoch 19/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9532 - loss: 0.0087\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.911999807925894e-05.\n",
      "284/284 [==============================] - 32s 112ms/step - auc: 0.9532 - loss: 0.0087 - val_auc: 0.9286 - val_loss: 0.0138 - lr: 1.1520e-04\n",
      "Epoch 20/30\n",
      "284/284 [==============================] - 31s 110ms/step - auc: 0.9566 - loss: 0.0084 - val_auc: 0.9141 - val_loss: 0.0180 - lr: 6.9120e-05\n",
      "Epoch 21/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9558 - loss: 0.0090\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.1471997974440455e-05.\n",
      "284/284 [==============================] - 33s 115ms/step - auc: 0.9558 - loss: 0.0090 - val_auc: 0.9291 - val_loss: 0.0141 - lr: 6.9120e-05\n",
      "Epoch 22/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9590 - loss: 0.0085Restoring model weights from the end of the best epoch.\n",
      "284/284 [==============================] - 34s 118ms/step - auc: 0.9590 - loss: 0.0085 - val_auc: 0.9271 - val_loss: 0.0138 - lr: 4.1472e-05\n",
      "Epoch 00022: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 2\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 52s 183ms/step - auc: 0.8210 - loss: 0.0198 - val_auc: 0.8724 - val_loss: 0.0134 - lr: 3.2000e-04\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 34s 118ms/step - auc: 0.8636 - loss: 0.0176 - val_auc: 0.8837 - val_loss: 0.0122 - lr: 3.2000e-04\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 35s 125ms/step - auc: 0.8738 - loss: 0.0154 - val_auc: 0.9051 - val_loss: 0.0109 - lr: 3.2000e-04\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 34s 121ms/step - auc: 0.8838 - loss: 0.0159 - val_auc: 0.8946 - val_loss: 0.0111 - lr: 3.2000e-04\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.8933 - loss: 0.0155\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00019199999514967202.\n",
      "284/284 [==============================] - 33s 115ms/step - auc: 0.8933 - loss: 0.0155 - val_auc: 0.8933 - val_loss: 0.0161 - lr: 3.2000e-04\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 35s 122ms/step - auc: 0.9063 - loss: 0.0138 - val_auc: 0.9230 - val_loss: 0.0100 - lr: 1.9200e-04\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 34s 120ms/step - auc: 0.9076 - loss: 0.0142 - val_auc: 0.9264 - val_loss: 0.0115 - lr: 1.9200e-04\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 34s 121ms/step - auc: 0.9118 - loss: 0.0140 - val_auc: 0.9182 - val_loss: 0.0105 - lr: 1.9200e-04\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9227 - loss: 0.0131\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00011519999534357338.\n",
      "284/284 [==============================] - 33s 116ms/step - auc: 0.9227 - loss: 0.0131 - val_auc: 0.9159 - val_loss: 0.0107 - lr: 1.9200e-04\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 34s 120ms/step - auc: 0.9227 - loss: 0.0128 - val_auc: 0.9119 - val_loss: 0.0117 - lr: 1.1520e-04\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9272 - loss: 0.0127\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.911999807925894e-05.\n",
      "284/284 [==============================] - 32s 112ms/step - auc: 0.9272 - loss: 0.0127 - val_auc: 0.9155 - val_loss: 0.0102 - lr: 1.1520e-04\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9327 - loss: 0.0123Restoring model weights from the end of the best epoch.\n",
      "284/284 [==============================] - 35s 124ms/step - auc: 0.9327 - loss: 0.0123 - val_auc: 0.9190 - val_loss: 0.0102 - lr: 6.9120e-05\n",
      "Epoch 00012: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 3\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 51s 179ms/step - auc: 0.8161 - loss: 0.0181 - val_auc: 0.8921 - val_loss: 0.0154 - lr: 3.2000e-04\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 32s 114ms/step - auc: 0.8577 - loss: 0.0151 - val_auc: 0.9083 - val_loss: 0.0163 - lr: 3.2000e-04\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 33s 116ms/step - auc: 0.8796 - loss: 0.0141 - val_auc: 0.9052 - val_loss: 0.0207 - lr: 3.2000e-04\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.8836 - loss: 0.0139\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00019199999514967202.\n",
      "284/284 [==============================] - 31s 111ms/step - auc: 0.8836 - loss: 0.0139 - val_auc: 0.9007 - val_loss: 0.0150 - lr: 3.2000e-04\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 34s 118ms/step - auc: 0.8956 - loss: 0.0126 - val_auc: 0.9136 - val_loss: 0.0139 - lr: 1.9200e-04\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 34s 119ms/step - auc: 0.9014 - loss: 0.0121 - val_auc: 0.9207 - val_loss: 0.0147 - lr: 1.9200e-04\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 32s 113ms/step - auc: 0.9091 - loss: 0.0120 - val_auc: 0.9199 - val_loss: 0.0148 - lr: 1.9200e-04\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 34s 120ms/step - auc: 0.9103 - loss: 0.0126 - val_auc: 0.9241 - val_loss: 0.0138 - lr: 1.9200e-04\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 33s 117ms/step - auc: 0.9096 - loss: 0.0123 - val_auc: 0.9310 - val_loss: 0.0130 - lr: 1.9200e-04\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 34s 119ms/step - auc: 0.9158 - loss: 0.0120 - val_auc: 0.9282 - val_loss: 0.0127 - lr: 1.9200e-04\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9168 - loss: 0.0120\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00011519999534357338.\n",
      "284/284 [==============================] - 32s 114ms/step - auc: 0.9168 - loss: 0.0120 - val_auc: 0.9147 - val_loss: 0.0146 - lr: 1.9200e-04\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 34s 118ms/step - auc: 0.9339 - loss: 0.0102 - val_auc: 0.9198 - val_loss: 0.0139 - lr: 1.1520e-04\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 35s 122ms/step - auc: 0.9302 - loss: 0.0104 - val_auc: 0.9349 - val_loss: 0.0120 - lr: 1.1520e-04\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 34s 121ms/step - auc: 0.9309 - loss: 0.0107 - val_auc: 0.9397 - val_loss: 0.0137 - lr: 1.1520e-04\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 34s 121ms/step - auc: 0.9374 - loss: 0.0106 - val_auc: 0.9328 - val_loss: 0.0122 - lr: 1.1520e-04\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9411 - loss: 0.0101\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.911999807925894e-05.\n",
      "284/284 [==============================] - 33s 116ms/step - auc: 0.9411 - loss: 0.0101 - val_auc: 0.9285 - val_loss: 0.0128 - lr: 1.1520e-04\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 33s 117ms/step - auc: 0.9449 - loss: 0.0098 - val_auc: 0.9346 - val_loss: 0.0128 - lr: 6.9120e-05\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9461 - loss: 0.0096\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.1471997974440455e-05.\n",
      "284/284 [==============================] - 33s 116ms/step - auc: 0.9461 - loss: 0.0096 - val_auc: 0.9371 - val_loss: 0.0125 - lr: 6.9120e-05\n",
      "Epoch 19/30\n",
      "284/284 [==============================] - ETA: 0s - auc: 0.9493 - loss: 0.0090Restoring model weights from the end of the best epoch.\n",
      "284/284 [==============================] - 35s 124ms/step - auc: 0.9493 - loss: 0.0090 - val_auc: 0.9366 - val_loss: 0.0129 - lr: 4.1472e-05\n",
      "Epoch 00019: early stopping\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Computing predictions...\n",
      "Generating submission.csv file...\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    \n",
    "    ''' Main modelling part with effnet, metadata, effnets, callbacks, optimizers etc.'''\n",
    "    \n",
    "    with strategy.scope():\n",
    "        \n",
    "        # meta implementation from here:\n",
    "        # https://www.kaggle.com/rajnishe/rc-fork-siim-isic-melanoma-384x384/notebook\n",
    "        \n",
    "        img_inp = tf.keras.layers.Input(shape = (CFG['inp_size'], CFG['inp_size'], 3), name = 'img_inp')\n",
    "        meta_inp = tf.keras.layers.Input(shape = (9), name = 'meta_inp')\n",
    "        \n",
    "        effs = [0,1,2,3,4,5,6,7]\n",
    "        eff = effs[CFG['eff_B']]\n",
    "        \n",
    "        constructor = getattr(efn, f'EfficientNetB{eff}')\n",
    "        efnetb = constructor(weights = 'noisy-student', include_top = False)     \n",
    "        \n",
    "        # attention implementation from here:\n",
    "        # https://www.kaggle.com/kmader/attention-on-pretrained-vgg16-for-bone-age/notebook\n",
    "        \n",
    "        pt_depth = efnetb.get_output_shape_at(0)[-1]\n",
    "        pt_features = efnetb(img_inp)\n",
    "        bn_features = tf.keras.layers.BatchNormalization()(pt_features)\n",
    "        \n",
    "        # here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "        attn_layer = tf.keras.layers.Conv2D(64, kernel_size = (1, 1), padding = 'same', activation = 'swish')(tf.keras.layers.Dropout(0.5)(bn_features))\n",
    "        attn_layer = tf.keras.layers.Conv2D(16, kernel_size = (1, 1), padding = 'same', activation = 'swish')(attn_layer)\n",
    "        attn_layer = tf.keras.layers.Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'swish')(attn_layer)\n",
    "        attn_layer = tf.keras.layers.Conv2D(1, kernel_size = (1, 1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "        \n",
    "        # fan it out to all of the channels\n",
    "        up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "        up_c2 = tf.keras.layers.Conv2D(pt_depth, kernel_size = (1, 1), padding = 'same',  activation = 'linear',  use_bias = False,    weights = [up_c2_w]  )\n",
    "        up_c2.trainable = False\n",
    "        attn_layer = up_c2(attn_layer)\n",
    "        mask_features = tf.keras.layers.multiply([attn_layer, bn_features])\n",
    "        gap_features = tf.keras.layers.GlobalAveragePooling2D()(mask_features)\n",
    "        gap_mask = tf.keras.layers.GlobalAveragePooling2D()(attn_layer)\n",
    "        \n",
    "         # To account for missing values from the attention model\n",
    "        gap = tf.keras.layers.Lambda(lambda x: x[0] / x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "        gap_dr = tf.keras.layers.Dropout(0.5)(gap)\n",
    "        dr_steps = tf.keras.layers.Dropout(0.25)(tf.keras.layers.Dense(128, activation = 'swish')(gap_dr))\n",
    "        \n",
    "        \n",
    "        \n",
    "        meta_layer = tf.keras.layers.Dense(16)(meta_inp)\n",
    "        meta_layer = tf.keras.layers.BatchNormalization()(meta_layer)\n",
    "        meta_layer = tf.keras.layers.Activation('swish')(meta_layer)\n",
    "        meta_layer = tf.keras.layers.Dropout(0.2)(meta_layer)\n",
    "        meta_layer = tf.keras.layers.Dense(8)(meta_inp)\n",
    "        meta_layer = tf.keras.layers.BatchNormalization()(meta_layer)\n",
    "        meta_layer = tf.keras.layers.Activation('swish')(meta_layer)\n",
    "        meta_layer = tf.keras.layers.Dropout(0.2)(meta_layer)\n",
    "        \n",
    "        concat = tf.keras.layers.concatenate([dr_steps, meta_layer])\n",
    "        concat = tf.keras.layers.BatchNormalization()(concat)\n",
    "        concat = tf.keras.layers.Dense(512, activation = 'swish')(concat)        \n",
    "        concat = tf.keras.layers.Dropout(0.15)(concat)\n",
    "        output = tf.keras.layers.Dense(1, activation = 'sigmoid',dtype='float32')(concat)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [img_inp, meta_inp], outputs = [output])\n",
    "\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = CFG['lr'])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = opt,\n",
    "            loss = [tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO,gamma = 2.0, alpha = 0.90)],\n",
    "            metrics = [tf.keras.metrics.AUC()]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    \n",
    "def train_validate_predict(df_sub, folds = 3):\n",
    "    \n",
    "    '''Training, validation, oof cv and predictions'''\n",
    "    \n",
    "    models = []\n",
    "    oof_image_name = []\n",
    "    oof_target = []\n",
    "    oof_prediction = []\n",
    "    \n",
    "   \n",
    "\n",
    "    kfold = KFold(folds, shuffle = True, random_state = 42)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(training_files)):\n",
    "        print('\\n')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        CFG['num_holes'] = 5 \n",
    "        CFG['side_length'] = CFG['inp_size']//10\n",
    "        train_dataset = get_training_dataset([training_files[x] for x in trn_ind], labeled = True, ordered = False)\n",
    "        val_dataset = get_validation_dataset([training_files[x] for x in val_ind], labeled = True, ordered = True)\n",
    "        K.clear_session()\n",
    "        model = get_model()\n",
    "        # early stopping with 5 patience\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_auc', mode = 'max', patience = 5, \n",
    "                                                      verbose = 2, min_delta = 0.00025, restore_best_weights = True)\n",
    "        # lr scheduler with 2 patience\n",
    "        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_auc', factor = 0.6, patience = 2 , verbose = 2, min_delta = 0.0005, min_lr=0.000001, mode = 'max')\n",
    "        history = model.fit(train_dataset, \n",
    "                            steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                            epochs = CFG['epochs'],\n",
    "                            callbacks = [sprinkles_cb, cb_lr_schedule, early_stopping],\n",
    "                            validation_data = val_dataset,\n",
    "                            verbose = 1)\n",
    "        models.append(model)\n",
    "        \n",
    "        # predict the validation set and save them for stacking\n",
    "        number_of_files = count_data_items([training_files[x] for x in val_ind])\n",
    "        dataset = get_complete_dataset([training_files[x] for x in val_ind])\n",
    "        # extracting image names\n",
    "        image_name = dataset.map(lambda image, image_name, target: image_name).unbatch()\n",
    "        image_name = next(iter(image_name.batch(number_of_files))).numpy().astype('U')\n",
    "        # extracting target variables\n",
    "        target = dataset.map(lambda image, image_name, target: target).unbatch()\n",
    "        target = next(iter(target.batch(number_of_files))).numpy()\n",
    "        # predicting validation set\n",
    "        image = dataset.map(lambda image, image_name, target: image)\n",
    "        probabilities = model.predict(image)\n",
    "        oof_image_name.extend(list(image_name))\n",
    "        oof_target.extend(list(target))\n",
    "        oof_prediction.extend(list(np.concatenate(probabilities)))\n",
    "\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    print('-'*50)\n",
    "    # saving OOF predictions\n",
    "    oof_df = pd.DataFrame({'image_name': oof_image_name, 'target': oof_target, 'predictions': oof_prediction})\n",
    "    oof_df.to_csv('OOF_EfficientNetB%i_%i.csv'%(CFG['eff_B'],CFG['inp_size']), index = False)\n",
    "        \n",
    "    # since we are splitting the dataset and iterating separately on images and ids, order matters.\n",
    "    test_ds = get_test_dataset(test_files, labeled = False, ordered = True)\n",
    "    test_images_ds = test_ds.map(lambda image, image_name: image)\n",
    "    \n",
    "    print('Computing predictions...')\n",
    "    probabilities = np.average([np.concatenate(models[i].predict(test_images_ds)) for i in range(folds)], axis = 0)\n",
    "    print('Generating submission.csv file...')\n",
    "    test_ids_ds = test_ds.map(lambda image, image_name: image_name).unbatch()\n",
    "\n",
    "    test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') \n",
    "    pred_df = pd.DataFrame({'image_name': test_ids, 'target': probabilities})\n",
    "    df_sub.drop('target', inplace = True, axis = 1)\n",
    "    df_sub = df_sub.merge(pred_df, on = 'image_name')\n",
    "    df_sub.to_csv('sub_EfficientNetB%i_%i.csv'%(CFG['eff_B'],CFG['inp_size']), index = False)\n",
    "    \n",
    "    return oof_target, oof_prediction\n",
    "    \n",
    "oof_target, oof_prediction = train_validate_predict(df_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.998935,
     "end_time": "2020-09-20T16:15:33.611715",
     "exception": false,
     "start_time": "2020-09-20T16:15:28.612780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OOF Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T16:15:43.373999Z",
     "iopub.status.busy": "2020-09-20T16:15:43.373306Z",
     "iopub.status.idle": "2020-09-20T16:15:43.411469Z",
     "shell.execute_reply": "2020-09-20T16:15:43.411941Z"
    },
    "papermill": {
     "duration": 4.842563,
     "end_time": "2020-09-20T16:15:43.412137",
     "exception": false,
     "start_time": "2020-09-20T16:15:38.569574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final OOF Roc Auc Score:  0.9322477716161036\n"
     ]
    }
   ],
   "source": [
    "# calculating oof roc auc score\n",
    "roc_auc = metrics.roc_auc_score(oof_target, oof_prediction)\n",
    "print('Final OOF Roc Auc Score: ', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-20T16:15:53.316947Z",
     "iopub.status.busy": "2020-09-20T16:15:53.316057Z",
     "iopub.status.idle": "2020-09-20T16:15:54.122554Z",
     "shell.execute_reply": "2020-09-20T16:15:54.121871Z"
    },
    "papermill": {
     "duration": 5.811486,
     "end_time": "2020-09-20T16:15:54.122663",
     "exception": false,
     "start_time": "2020-09-20T16:15:48.311177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7036\r\n",
      "-rw-r--r-- 1 root root 1603910 Sep 20 16:14 OOF_EfficientNetB0_256.csv\r\n",
      "---------- 1 root root 5330610 Sep 20 16:15 __notebook__.ipynb\r\n",
      "-rw-r--r-- 1 root root  262896 Sep 20 16:15 sub_EfficientNetB0_256.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.898783,
     "end_time": "2020-09-20T16:16:03.917441",
     "exception": false,
     "start_time": "2020-09-20T16:15:59.018658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Words\n",
    "\n",
    "### It was a great experience for me to be in part of this competition. I learnt a lot from this community, especially people like Chris with their tireless sharings made this work much more easier for me.\n",
    "\n",
    "### Thanks to all who contributed and thank you for reading, happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2310.417298,
   "end_time": "2020-09-20T16:16:09.930716",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-20T15:37:39.513418",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
